{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# linear algebra\n",
    "import numpy as np\n",
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd\n",
    "#plt.style.use(\"seaborn-whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "import warnings                                            # Ignore warning related to pandas_profiling\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "def annot_plot(ax,w,h):                                    # function to add data to plot\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for p in ax.patches:\n",
    "         ax.annotate(f\"{p.get_height() * 100 / df_watson.shape[0]:.2f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "         ha='center', va='center', fontsize=11, color='black', rotation=0, xytext=(0, 10),\n",
    "         textcoords='offset points')             \n",
    "def annot_plot_num(ax,w,h):                                    # function to add data to plot\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate('{0:.1f}'.format(p.get_height()), (p.get_x()+w, p.get_height()+h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson = pd.read_csv(\"/kaggle/input/ibm-watson-marketing-customer-value-data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Customer ID from data set.\n",
    "df_watson=df_watson.drop(columns=['Customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many details in the data set provided: :\n",
    "\n",
    "There are 9134 Observations of 24 Variable\n",
    "There are mix of categorical and continous DataType.\n",
    "Dependent Variable is Customer Life Time Value as we have to predict the CLV.\n",
    "Continues Independed Variables are : CustomerLifetimeValue, Income,MonthlyPremiumAuto, MonthsSinceLastClaim, MonthsSincePolicyInception, NumberofOpenComplaints, NumberofPolicies, TotalClaimAmount\n",
    "Independent Variables are: Customer, StateCustomerLifetimeValue, Response, Coverage, Education, EffectiveToDate, EmploymentStatus, Gender, Income, LocationCode, MaritalStatus, MonthlyPremiumAuto, MonthsSinceLastClaim, MonthsSincePolicyInception, NumberofOpenComplaints, NumberofPoliciesPolicyType, Policy, RenewOfferType, SalesChannel, TotalClaimAmountVehicleClass, VehicleSize\n",
    "There is no null value. So we will not assign or drop any value. \n",
    "The \"customer\" column is the serial number, so it is unimportant for analysis and is removed from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values in each column and storing the value in a data frame na_counts\n",
    "total = df_watson.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = df_watson.isnull().sum()/df_watson.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are no null values, so no further action required to replace missing or null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_watson.apply(lambda col: col.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Values of each column\n",
    "df_watson.astype('object').describe(include='all').loc['unique', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section we perform initial investigations on insurance data so as to discover patterns and to check assumptions with the help of summary statistics and graphical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Customer Lifetime Value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing statistics module \n",
    "from statistics import variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Customer Lifetime Value'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Customer Lifetime Value'].kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_amount1 = (max(df_watson['Customer Lifetime Value']) - min(df_watson['Customer Lifetime Value'])) / 100\n",
    "plt.hist(df_watson['Customer Lifetime Value'], bins=int(round(bin_amount1)))\n",
    "plt.xlabel('CLV')\n",
    "plt.ylabel('Density')\n",
    "plt.title('CLV Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum CLV is  83325.381andtheminimumCLVis 1898.008.\n",
    "## Mean of CLV is  8005andtheMedianis 5780.\n",
    "## The Variance in CLV is 47210196 and the Standard Deviation is 6870.968.\n",
    "## Skewness is 4.031284. CLV is positive skewed and most values are concentrated on the left of\n",
    "## the mean value, yet all the extreme values are on the right of the mean value.\n",
    "## Kurtosis is 13.81163. Since kurtosis > 3, means distribution has thicker tails than normal\n",
    "## distribution and have more outliers (extreme values).\n",
    "## This means that the distribution of CLV is positively skewed (as expected) and is heavily\n",
    "## Leptokurtic.\n",
    "## These results indicate a distribution that is heavily skewed with a very large tail.\n",
    "## There are a LOT of Customers with low CLV. Very few customers with high CLV.\n",
    "## This can be visually understood using the Histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Descriptive Analysis of Monthly Premium Auto(MPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Monthly Premium Auto'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance(df_watson['Monthly Premium Auto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Monthly Premium Auto'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Monthly Premium Auto'].kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Monthly Premium Auto'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_amount2 = (max(df_watson['Monthly Premium Auto']) - min(df_watson['Monthly Premium Auto'])) / 1\n",
    "plt.hist(df_watson['Monthly Premium Auto'], bins=int(round(bin_amount2)))\n",
    "plt.xlabel('Monthly Premium')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Monthly Premium Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Monthly Premium Auto'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Monthly Premium Auto')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of MPA vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum MPA is 298 and the minimum MPA is 61\n",
    "## Mean of MPA is 93.21929 and the Median is 84.00\n",
    "## The Variance in MPA is 1183.908 and the Standard Deviation is 34.40797\n",
    "## Skewness is 2.122849. MPA is positive skewed and most values are concentrated on the left of\n",
    "## the mean value, yet all the extreme values are on the right of the mean value.\n",
    "## Kurtosis is 6.187546. Since kurtosis > 3, means distribution has thicker tails than normal\n",
    "## distribution and have more outliers (extreme values).\n",
    "## There is a Positive Corelation of 39.62 % of MPA with CLV. From scatter plot, it is clearly\n",
    "## visible that on MPA, CLV is also Increasing.7.\n",
    "## Monthly premiums follow a trend similar to CLV although the distribution is NOT as skewed\n",
    "## or as long tailed as CLV. This can be visually seen in the Histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. Descriptive Analysis ofTotalClaimAmount (TCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Total Claim Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance(df_watson['Total Claim Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Total Claim Amount'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Total Claim Amount'].kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Total Claim Amount'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_amount3 = (max(df_watson['Total Claim Amount']) - min(df_watson['Total Claim Amount'])) / 10\n",
    "plt.hist(df_watson['Total Claim Amount'], bins=int(round(bin_amount3)),color='red')\n",
    "plt.xlabel('Total Claim Amount')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Total Claim Amount Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Total Claim Amount'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Total Claim Amount')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of TCA vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum TCA is  0.099007andtheminimumTCAis 2893.239678\n",
    "## Mean of TCA is  434.0888andtheMedianis 383.945\n",
    "## The Variance in TCA is 84390.3 and the Standard Deviation is 290.5001\n",
    "## Skewness is 1.714403. TCA is positive skewed and most values are concentrated on the left of\n",
    "## the mean value, yet all the extreme values are on the right of the mean value.\n",
    "## Kurtosis is 5.973506. Since kurtosis > 3, means TCA distribution has thicker tails than normal\n",
    "## distribution and have more outliers (extreme values).\n",
    "## There is a Positive Corelation of 22.65 % of TCA with CLV. From scatter plot, it is clearly\n",
    "## visible that on TCA, CLV is also Increasing.\n",
    "## Total Claim amounts also follow a trend similar to CLV and MPA although the distribution is\n",
    "## NOT as skewed or as long tailed as MPA. This can be visually seen in the Histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This means that variation in data is CLV > MPA > TCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Descriptive Analysis of other variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Income'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Income'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of Income vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Months Since Last Claim'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Months Since Last Claim'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Months Since Last Claim')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of Months Since Last Claim vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Months Since Policy Inception'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Months Since Policy Inception'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Months Since Policy Inception')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of Months Since Policy Inception vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Number of Open Complaints'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Number of Open Complaints'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Number of Open Complaints')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of Number of Open Complaints vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watson['Number of Policies'].corr(df_watson['Customer Lifetime Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_watson['Number of Policies'], df_watson['Customer Lifetime Value'], 'bo')\n",
    "plt.xlabel('Number of Policies')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Scatterplot of Number of Policies vs CLV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The positive correlation values close to zero show that that there is no strong relationship of Income, MonthsSinceLastClaim, NumberofPolicies etc with CLV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inferential Statistics\n",
    "The most obvious candidate for Dependent Variable is CLV (CustomerLifetimeValue). This also makes sense from a Business Perspective as we want to understand what contributes to making a high value customer (Descriptive analysis) and maybe later on predict who is going to be high value customer (Predictive analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.01 Effect of Insurance Coverage on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Coverage', data = df_watson)\n",
    "plt.xlabel('Coverage')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Coverage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Coverage', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Coverage', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Coverage')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Coverage')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.02 Effect of Education on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Education', data = df_watson)\n",
    "plt.xlabel('Education')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Education')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Education', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][4] = 100 * agg_arr[4] / agg_arr_sum\n",
    "\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Education', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Education')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Education')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Educated customers (with a bachelors or equivalent degree) are more valuable than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.03 Effect of Employment Status on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'EmploymentStatus', data = df_watson)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Employment Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('EmploymentStatus', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][4] = 100 * agg_arr[4] / agg_arr_sum\n",
    "\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='EmploymentStatus', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('EmploymentStatus')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by EmploymentStatus')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employed customers are more valuable than others as compared to Retired, Unemployed or Disabled Customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.04 Effect of Gender on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Gender', data = df_watson)\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Gender', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Gender', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Gender')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender has no role to play in determining the value of a customer. Both Male and Female looks valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.05 Effect of Location on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Location Code', data = df_watson)\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Location Code', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Location Code', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Location Code')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Location Code')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rural customers are LESS valuable than Urban customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.06 Effect of Marital Status on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Marital Status', data = df_watson)\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Marital Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Marital Status', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Marital Status', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Marital Status')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Married customers are buying more auto insurance and adding more value to company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.07 Effect of Policy Type on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Policy Type', data = df_watson)\n",
    "plt.xlabel('Policy Type')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Policy Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Policy Type', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Policy Type', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Policy Type')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Policy Type')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers having thier own Persoanl Policy are more valuable to company then Corporate and Special Insurance policy holder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.08 Effect of Renew Offer Type on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Renew Offer Type', data = df_watson)\n",
    "plt.xlabel('Renew Offer Type')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Renew Offer Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Renew Offer Type', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Renew Offer Type', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Renew Offer Type')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Renew Offer Type')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offers 1 and Offer 2 attracts more customers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.09 Effect of Sales Channel on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Sales Channel', data = df_watson)\n",
    "plt.xlabel('Sales Channel')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Sales Channel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Sales Channel', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Sales Channel', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Sales Channel')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Sales Channel')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Center is not performing well comparerd to other channels throughout the country (in terms of high value customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.10 Effect of Vehicle Class on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Vehicle Class', data = df_watson)\n",
    "plt.xlabel('Vehicle Class')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Vehicle Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Vehicle Class', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][4] = 100 * agg_arr[4] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][5] = 100 * agg_arr[5] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Vehicle Class', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Vehicle Class')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Vehicle Class')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers having Four-Door car and SUV are more valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.11 Effect of Vehicle Size on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Vehicle Size', data = df_watson)\n",
    "plt.xlabel('Vehicle Size')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Vehicle Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Vehicle Size', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Vehicle Size', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Vehicle Size')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Vehicle Size')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers having Mid Size vehicals are adding more value to Insurance company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.12 Effect of States on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'State', data = df_watson)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt State')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('State', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][4] = 100 * agg_arr[4] / agg_arr_sum\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='State', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by State')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California customers are more valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.13 Effect of Policy on Customer Life Time Value (CLV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y = 'Customer Lifetime Value' , x = 'Policy', data = df_watson)\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Customer Lifetime Value')\n",
    "plt.title('Visualization of CLV wrt Policy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_watson.groupby('Policy', as_index=False).agg({\"Customer Lifetime Value\": \"sum\"})\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_arr_sum = sum(df_agg['Customer Lifetime Value'])\n",
    "agg_arr = df_agg['Customer Lifetime Value']\n",
    "percentile_agg_arr = []\n",
    "df_agg['Customer Lifetime Value'][0] = 100 * agg_arr[0] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][1] = 100 * agg_arr[1] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][2] = 100 * agg_arr[2] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][3] = 100 * agg_arr[3] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][4] = 100 * agg_arr[4] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][5] = 100 * agg_arr[5] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][6] = 100 * agg_arr[6] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][7] = 100 * agg_arr[7] / agg_arr_sum\n",
    "df_agg['Customer Lifetime Value'][8] = 100 * agg_arr[8] / agg_arr_sum\n",
    "\n",
    "\n",
    "#agg_arr_sum\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Policy', y='Customer Lifetime Value', data=df_agg)\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('CLV in Percentage')\n",
    "plt.title('CLV Distribution by Policy')\n",
    "plt.ylim(0, 100)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%d %%'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal L3 Policy is adding more value to company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Regression Analysis with Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df_watson.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['State','Coverage','Renew Offer Type','Vehicle Class','Response','Gender','Location Code','Vehicle Size','Policy','Policy Type','Sales Channel','Effective To Date'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although months since policy inception, months since last claim, number of open complaints and number of policies are all numerical we will consider them as categorical features while preparing the model because numerical values are not high.\n",
    "\n",
    "Firstly, according to our EDA, we saw that the number of policies >= 3 have similar trend so we will group all of them as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clv = pd.get_dummies(df,columns=['Marital Status','Number of Policies','Education','EmploymentStatus'],drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dummies of chosen categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check continious variables and relations of them with categorical variables to see if there is any possibility to create new categorical variables from continuous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"Income\", y=\"Customer Lifetime Value\", hue=\"State\",\n",
    "                     data=df_watson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maritalstts = sns.scatterplot(x=\"Income\", y=\"Customer Lifetime Value\", hue=\"EmploymentStatus\",\n",
    "                     data=df_watson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"Total Claim Amount\", y=\"Customer Lifetime Value\", hue=\"Marital Status\",\n",
    "                     data=df_watson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from datetime import datetime\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no obvious pattern to create new categorical variable from continious variables. So far, I have explored the dataset in detail and got familiar with it. Now it is time to create the model and see if I can predict Customer Life Time Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = df_clv['Customer Lifetime Value']\n",
    "x = df_clv.drop('Customer Lifetime Value',axis=1)\n",
    "\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "results = sm.OLS(y, x).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I will split my dataset into training and testing data which means I will select 30% of the data randomly and separate it from the training data. (test_size shows the percentage of the test data  30%) (If you dont specify the random_state in your code, then every time you run (execute) your code, a new random value is generated and training and test datasets would have different values each time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "print('Train Data Count: {}'.format(X_train.shape[0]))\n",
    "print('Test Data Count: {}'.format(X_test.shape[0]))\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model graph to see predictions\n",
    "\n",
    "\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "y_pred = results.predict(X_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual LTV\")\n",
    "plt.ylabel(\"Estimated LTV\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see their errors\n",
    "\n",
    "print(\"Mean Absolute Error (MAE)        : {}\".format(mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(y_test, y_pred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)     : {}\".format(rmse(y_test, y_pred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE) : {}\".format(np.mean(np.abs((y_test - y_pred) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv_score = []\n",
    "\n",
    "clv_score.append((results.rsquared,\n",
    "                  mean_absolute_error(y_test, y_pred),\n",
    "                 mse(y_test, y_pred),rmse(y_test, y_pred),\n",
    "                 np.mean(np.abs((y_test - y_pred) / y_test)) * 100))\n",
    "clv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate the original data and get the log version of it to be able to reach higher R2(with outliers)\n",
    "df2 = df_clv.copy()\n",
    "\n",
    "df2['Monthly Premium Auto'] = np.log(df['Monthly Premium Auto'])\n",
    "df2['Total Claim Amount'] = np.log(df['Total Claim Amount'])\n",
    "y = np.log(df2['Customer Lifetime Value'])\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "X2 =  df2.drop('Customer Lifetime Value',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "print('Train Data Count: {}'.format(X2_train.shape[0]))\n",
    "print('Test Data Count: {}'.format(X2_test.shape[0]))\n",
    "\n",
    "X2_train = sm.add_constant(X2_train)\n",
    "results_log = sm.OLS(y_train, X2_train).fit()\n",
    "results_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model graph to see predictions\n",
    "\n",
    "\n",
    "X2_test = sm.add_constant(X2_test)\n",
    "\n",
    "y_pred = results_log.predict(X2_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual ltv\")\n",
    "plt.ylabel(\"Estimated ltv\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV-Log Transformation with outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error (MAE)        : {}\".format(mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(y_test, y_pred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)     : {}\".format(rmse(y_test, y_pred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE) : {}\".format(np.mean(np.abs((y_test - y_pred) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ypred = np.exp(y_pred)\n",
    "exp_ytest = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error (MAE)        : {}\".format(mean_absolute_error(exp_ytest, exp_ypred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(exp_ytest, exp_ypred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)     : {}\".format(rmse(exp_ytest, exp_ypred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE) : {}\".format(np.mean(np.abs((exp_ytest - exp_ypred) / exp_ytest)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv_score.append((results.rsquared,\n",
    "                  mean_absolute_error(exp_ytest, exp_ypred),\n",
    "                 mse(exp_ytest, exp_ypred),rmse(exp_ytest, exp_ypred),\n",
    "                 np.mean(np.abs((exp_ytest - exp_ypred) / exp_ytest)) * 100))\n",
    "clv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate the original data and winsorize the data at %5\n",
    "df3 = df_clv.copy()\n",
    "\n",
    "df3['Monthly Premium Auto'] = winsorize(df3['Monthly Premium Auto'],(0, 0.05))\n",
    "df3['Total Claim Amount'] = winsorize(df3['Total Claim Amount'],(0, 0.05))\n",
    "\n",
    "\n",
    "y = df3['Customer Lifetime Value']\n",
    "X3 =  df3.drop('Customer Lifetime Value',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y_train, y_test = train_test_split(X3, y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "print('Train Data Count: {}'.format(X3_train.shape[0]))\n",
    "print('Test Data Count: {}'.format(X3_test.shape[0]))\n",
    "\n",
    "\n",
    "X3_train = sm.add_constant(X3_train)\n",
    "results_wins = sm.OLS(y_train, X3_train).fit()\n",
    "results_wins.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model graph to see predictions\n",
    "\n",
    "\n",
    "X3_test = sm.add_constant(X3_test)\n",
    "\n",
    "y_pred = results_wins.predict(X3_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual LTV\")\n",
    "plt.ylabel(\"Estimated LTV\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV-5% Winsorize\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error (MAE)        : {}\".format(mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(y_test, y_pred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)     : {}\".format(rmse(y_test, y_pred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE) : {}\".format(np.mean(np.abs((y_test - y_pred) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv_score.append((results_wins.rsquared,\n",
    "                  mean_absolute_error(y_test, y_pred),\n",
    "                 mse(y_test, y_pred),rmse(y_test, y_pred),\n",
    "                 np.mean(np.abs((y_test - y_pred) / y_test)) * 100))\n",
    "clv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate the original data and take log of the data without outlier\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "\n",
    "df4['Monthly Premium Auto'] = np.log(df4['Monthly Premium Auto'])\n",
    "df4['Total Claim Amount'] = np.log(df4['Total Claim Amount'])\n",
    "\n",
    "\n",
    "y = np.log(df4['Customer Lifetime Value'])\n",
    "X4 =df4.drop('Customer Lifetime Value',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train, X4_test, y_train, y_test = train_test_split(X4, y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "print('Train Data Count: {}'.format(X4_train.shape[0]))\n",
    "print('Test Data Count: {}'.format(X4_test.shape[0]))\n",
    "\n",
    "\n",
    "X4_train = sm.add_constant(X4_train)\n",
    "results_logwins = sm.OLS(y_train, X4_train).fit()\n",
    "results_logwins.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model graph to see predictions\n",
    "\n",
    "\n",
    "X4_test = sm.add_constant(X4_test)\n",
    "\n",
    "y_pred = results_logwins.predict(X4_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual LTV\")\n",
    "plt.ylabel(\"Estimated LTV\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV- Both Log Transformation & 5% Winsorize\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error (MAE)        : {}\".format(mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(y_test, y_pred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)     : {}\".format(rmse(y_test, y_pred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE) : {}\".format(np.mean(np.abs((y_test - y_pred) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ypred = np.exp(y_pred)\n",
    "exp_ytest = np.exp(y_test)\n",
    "\n",
    "clv_score.append((results_logwins.rsquared,\n",
    "                  mean_absolute_error(exp_ytest, exp_ypred),\n",
    "                 mse(exp_ytest, exp_ypred),rmse(exp_ytest, exp_ypred),\n",
    "                 np.mean(np.abs((exp_ytest - exp_ypred) / exp_ytest)) * 100))\n",
    "clv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best model is the one with log transformation and outliers included\n",
    "\n",
    "#Let's use polynomial features to see if we can do better\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "y = np.log(df2['Customer Lifetime Value'])\n",
    "X5 =df2.drop('Customer Lifetime Value',axis=1)\n",
    "\n",
    "\n",
    "pol = PolynomialFeatures()\n",
    "\n",
    "\n",
    "array = pol.fit_transform(X5)\n",
    "\n",
    "df_pol = pd.DataFrame(array)\n",
    "df_pol.columns = pol.get_feature_names(X5.columns)\n",
    "df_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_train, df_pol_test, y_train, y_test = train_test_split(df_pol, y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "print('Train Data Count: {}'.format(df_pol_train.shape[0]))\n",
    "print('Test Data Count: {}'.format(df_pol_test.shape[0]))\n",
    "\n",
    "df_pol_train = sm.add_constant(df_pol_train)\n",
    "results_pol = sm.OLS(y_train, df_pol_train).fit()\n",
    "results_pol.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_test = sm.add_constant(df_pol_test)\n",
    "\n",
    "y_pred = results_pol.predict(df_pol_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual ltv\")\n",
    "plt.ylabel(\"Estimated ltv\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV-Polynomial Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_test = sm.add_constant(df_pol_test)\n",
    "\n",
    "y_pred = results_pol.predict(df_pol_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual ltv\")\n",
    "plt.ylabel(\"Estimated ltv\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV-Polynomial Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error (MAE)     : {}\".format(mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(y_test, y_pred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)    : {}\".format(rmse(y_test, y_pred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE)  : {}\".format(np.mean(np.abs((y_test - y_pred) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ypred = np.exp(y_pred)\n",
    "exp_ytest = np.exp(y_test)\n",
    "\n",
    "clv_score.append((results_pol.rsquared,\n",
    "                  mean_absolute_error(exp_ytest, exp_ypred),\n",
    "                 mse(exp_ytest, exp_ypred),rmse(exp_ytest, exp_ypred),\n",
    "                 np.mean(np.abs((exp_ytest - exp_ypred) / exp_ytest)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model graph to see exponential version of predictions\n",
    "\n",
    "\n",
    "df_pol_test = sm.add_constant(df_pol_test)\n",
    "\n",
    "y_pred = np.exp(results_pol.predict(df_pol_test))\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(exp_ytest, y_pred)\n",
    "plt.plot(exp_ytest, exp_ytest, color=\"red\")\n",
    "plt.xlabel(\"Actual ltv\")\n",
    "plt.ylabel(\"Estimated ltv\", )\n",
    "plt.title(\"Actual vs Estimated Customer LTV-Polynomial Features-Exp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual scores and predicted scores have good linearity but after some point we see that linearity is not good enough. In the graph, it is seen that customer life time value prediction is better with the values lower than 10.000.Lets check if there is any improvement on mean sq error term when we predict customer LTV lower than 10.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse( y_test[y_test<10],y_pred[y_test<10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some improvements when we get polynomial feautures into the scene. However, there are some insignificant features in the model that p-values are more than 0.05. Thats why we will build a new model by removing insignificant features towards target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    significant_features = list(results_pol.pvalues[results_pol.pvalues <= 0.05].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig_train, df_sig_test, y_train, y_test = train_test_split(df_pol[significant_features], y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "print('Train Data Count: {}'.format(df_sig_train.shape[0]))\n",
    "print('Test Data Count: {}'.format(df_sig_test.shape[0]))\n",
    "\n",
    "df_sig_train = sm.add_constant(df_sig_train)\n",
    "results_sig = sm.OLS(y_train, df_sig_train).fit()\n",
    "results_sig.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model graph to see predictions\n",
    "\n",
    "\n",
    "df_sig_test = sm.add_constant(df_sig_test)\n",
    "\n",
    "y_pred = results_sig.predict(df_sig_test)\n",
    "sns.set(color_codes=True)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, y_test, color=\"red\")\n",
    "plt.xlabel(\"Actual LTV\")\n",
    "plt.ylabel(\"Estimated LTV\" )\n",
    "plt.title(\"Actual vs Estimated Customer LTV-Polynomial Features with significant variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error (MAE)        : {}\".format(mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Mean Sq. Error (MSE)          : {}\".format(mse(y_test, y_pred)))\n",
    "print(\"Root Mean Sq. Error (RMSE)     : {}\".format(rmse(y_test, y_pred)))\n",
    "print(\"Mean Abs. Perc. Error (MAPE) : {}\".format(np.mean(np.abs((y_test - y_pred) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ypred = np.exp(y_pred)\n",
    "exp_ytest = np.exp(y_test)\n",
    "\n",
    "clv_score.append((results_sig.rsquared,\n",
    "                  mean_absolute_error(exp_ytest, exp_ypred),\n",
    "                 mse(exp_ytest, exp_ypred),rmse(exp_ytest, exp_ypred),\n",
    "                 np.mean(np.abs((exp_ytest - exp_ypred) / exp_ytest)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clvscore = pd.DataFrame(clv_score)\n",
    "df_clvscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clvscore.index = ['Standard','Log with outliers','Without Outliers','Log without outliers',\n",
    "                       'Polynomial Features',\n",
    "                       'Polynomial with significant features']\n",
    "\n",
    "df_clvscore.columns = ['R2', 'MAE', 'MSE','RMSE','MAPE']\n",
    "\n",
    "\n",
    "df_clvscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "### Similarities: Both MAE and RMSE express average model prediction error in units of the variable of interest. Both metrics can range from 0 to  and are indifferent to the direction of errors. They are negatively-oriented scores, which means lower values are better.\n",
    "### Differences: Taking the square root of the average squared errors has some interesting implications for RMSE. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable. The three tables below show examples where MAE is steady and RMSE increases as the variance associated with the frequency distribution of error magnitudes also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(df_pol_train, y_train)\n",
    "\n",
    "y_train_predict = lrm.predict(df_pol_train)\n",
    "y_test_predict = lrm.predict(df_pol_test)\n",
    "\n",
    "print(\"Train observation number  : {}\".format(df_pol_train.shape[0]))\n",
    "print(\"Test observation number   : {}\".format(df_pol_test.shape[0]), \"\\n\")\n",
    "\n",
    "print(\"Train R-Square  : {}\".format(lrm.score(df_pol_train, y_train)))\n",
    "print(\"-----Test Scores---\")\n",
    "print(\"Test R-Square   : {}\".format(lrm.score(df_pol_test, y_test)))\n",
    "print(\"Mean_absolute_error (MAE)             : {}\".format(mean_absolute_error(y_test, y_test_predict)))\n",
    "print(\"Mean squared error (MSE)              : {}\".format(mse(y_test, y_test_predict)))\n",
    "print(\"Root mean squared error(RMSE)         : {}\".format(rmse(y_test, y_test_predict)))\n",
    "print(\"Mean absolute percentage error (MAPE) : {}\".format(np.mean(np.abs((y_test - y_test_predict) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "\n",
    "# Create the train and test data\n",
    "df_pol_train, df_pol_test, y_train, y_test = train_test_split(df_pol, y, test_size = 0.30, random_state = 450)\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "model = Lasso()\n",
    "visualizer = PredictionError(model)\n",
    "\n",
    "visualizer.fit(df_pol_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(df_pol_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show()                 # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "Model = Ridge()\n",
    "visualizer_residual = ResidualsPlot(Model)\n",
    "\n",
    "visualizer_residual.fit(df_pol_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer_residual.score(df_pol_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer_residual.show()                 # Finaliz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "We have created six different models to reach the best model with highest R-square and lower error terms.\n",
    "\n",
    "In the light of comparison table, we could choose to go for the 5th model which have both log transformation and polynomial features. We see that R square is 0.91 means that 91% of the variance can be explained, which is really high.\n",
    "\n",
    "It seems like I predict values really good! Actual scores and predicted scores have good linearity but after some point we see that linearity is not good enough. In the graph, it is seen that customer life time value prediction is better with the values lower than 10.000. If we predict customer LTV lower than 10.000, we see that Mean Sq. Error decreased from 0.04 to 0.02 which is almost half of the initial error.\n",
    "\n",
    "We do not see overfitting problem with the model but still I have checked Lasso and Ridge models to see if there is any change on the model.\n",
    "\n",
    "From marketing perspective, we have a better opinion which customer have higher predicted life time value. With that information it is easier to lead marketing activities into more profitable scale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
