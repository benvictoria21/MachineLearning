{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Reinforcement Learning.ipynb","provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyMwhY76hsY+YRA8DCYx2dhz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OxlIdQbzYvDc","colab_type":"code","colab":{}},"source":["import gym # all you have to do to import and use open ai gym "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BU5rYLqHbfof","colab_type":"code","colab":{}},"source":["env = gym.make('FrozenLake-v0')  # we are going to use the FrozenLake enviornment"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_VHLKaXcE_G","colab_type":"code","colab":{}},"source":["env.reset()  # reset enviornment to default state"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kqtqniNcIrf","colab_type":"code","colab":{}},"source":["action = env.action_space.sample()  # get a random action "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpMZ_WAicXl1","colab_type":"code","colab":{}},"source":["env.render()   # render the GUI for the enviornment "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8GVNpzNcZEI","colab_type":"code","colab":{}},"source":["import gym\n","import numpy as np\n","import time\n","\n","env = gym.make('FrozenLake-v0')\n","STATES = env.observation_space.n\n","ACTIONS = env.action_space.n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7ae0IONdAAC","colab_type":"code","colab":{}},"source":["Q = np.zeros((STATES, ACTIONS))  # create a matrix with all 0 values \n","Q"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWBFH--ddDv9","colab_type":"code","colab":{}},"source":["EPISODES = 2000 # how many times to run the enviornment from the beginning\n","MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n","\n","LEARNING_RATE = 0.81  # learning rate\n","GAMMA = 0.96"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPkzs-H4eqB8","colab_type":"code","colab":{}},"source":["epsilon = 0.9  # start with a 90% chance of picking a random action\n","\n","# code to pick action\n","if np.random.uniform(0, 1) < epsilon:  # we will check if a randomly selected value is less than epsilon.\n","    action = env.action_space.sample()  # take random action\n","else:\n","    action = np.argmax(Q[state, :])  # use Q table to pick best action based on current value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"olN7p5ONe5bH","colab_type":"code","colab":{}},"source":["import gym\n","import numpy as np\n","import time\n","\n","env = gym.make('FrozenLake-v0')\n","STATES = env.observation_space.n\n","ACTIONS = env.action_space.n\n","\n","Q = np.zeros((STATES, ACTIONS))\n","\n","EPISODES = 1500 # how many times to run the enviornment from the beginning\n","MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n","\n","LEARNING_RATE = 0.81  # learning rate\n","GAMMA = 0.96\n","\n","RENDER = False # if you want to see training set to true\n","\n","epsilon = 0.9"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EWdyS3AXe_26","colab_type":"code","colab":{}},"source":["import gym\n","import numpy as np\n","import time\n","\n","env = gym.make('FrozenLake-v0')\n","STATES = env.observation_space.n\n","ACTIONS = env.action_space.n\n","\n","Q = np.zeros((STATES, ACTIONS))\n","\n","EPISODES = 1500 # how many times to run the enviornment from the beginning\n","MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n","\n","LEARNING_RATE = 0.81  # learning rate\n","GAMMA = 0.96\n","\n","RENDER = False # if you want to see training set to true\n","\n","epsilon = 0.9"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"amZ5xjb1gLDm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}