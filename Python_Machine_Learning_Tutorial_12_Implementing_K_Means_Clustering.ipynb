{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Machine Learning Tutorial #12 - Implementing K-Means Clustering",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOKHlbepwLLdcbjvyrWfUq/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benvictoria21/python-machine-learning/blob/master/Python_Machine_Learning_Tutorial_12_Implementing_K_Means_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FY_d-EzfadI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIaAXV35gKZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = load_digits()\n",
        "data = scale(digits.data)\n",
        "y = digits.target\n",
        "\n",
        "k = 10\n",
        "samples, features = data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu7DZqC9gMww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bench_k_means(estimator, name, data):\n",
        "    estimator.fit(data)\n",
        "    print('%-9s\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
        "          % (name, estimator.inertia_,\n",
        "             metrics.homogeneity_score(y, estimator.labels_),\n",
        "             metrics.completeness_score(y, estimator.labels_),\n",
        "             metrics.v_measure_score(y, estimator.labels_),\n",
        "             metrics.adjusted_rand_score(y, estimator.labels_),\n",
        "             metrics.adjusted_mutual_info_score(y,  estimator.labels_),\n",
        "             metrics.silhouette_score(data, estimator.labels_,\n",
        "                                      metric='euclidean')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9RXF-gXgVSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = KMeans(n_clusters=k, init=\"random\", n_init=10)\n",
        "bench_k_means(clf, \"1\", data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2No80MkDgWzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "digits = load_digits()\n",
        "data = scale(digits.data)\n",
        "\n",
        "n_samples, n_features = data.shape\n",
        "n_digits = len(np.unique(digits.target))\n",
        "labels = digits.target\n",
        "\n",
        "sample_size = 300\n",
        "\n",
        "print(\"n_digits: %d, \\t n_samples %d, \\t n_features %d\"\n",
        "      % (n_digits, n_samples, n_features))\n",
        "\n",
        "\n",
        "print(82 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
        "\n",
        "\n",
        "def bench_k_means(estimator, name, data):\n",
        "    t0 = time()\n",
        "    estimator.fit(data)\n",
        "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
        "          % (name, (time() - t0), estimator.inertia_,\n",
        "             metrics.homogeneity_score(labels, estimator.labels_),\n",
        "             metrics.completeness_score(labels, estimator.labels_),\n",
        "             metrics.v_measure_score(labels, estimator.labels_),\n",
        "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
        "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
        "             metrics.silhouette_score(data, estimator.labels_,\n",
        "                                      metric='euclidean',\n",
        "                                      sample_size=sample_size)))\n",
        "\n",
        "bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),\n",
        "              name=\"k-means++\", data=data)\n",
        "\n",
        "bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),\n",
        "              name=\"random\", data=data)\n",
        "\n",
        "\n",
        "print(82 * '_')\n",
        "\n",
        "# #############################################################################\n",
        "# Visualize the results on PCA-reduced data\n",
        "\n",
        "reduced_data = PCA(n_components=2).fit_transform(data)\n",
        "kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
        "kmeans.fit(reduced_data)\n",
        "\n",
        "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
        "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
        "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Obtain labels for each point in mesh. Use last trained model.\n",
        "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1)\n",
        "plt.clf()\n",
        "plt.imshow(Z, interpolation='nearest',\n",
        "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "           cmap=plt.cm.Paired,\n",
        "           aspect='auto', origin='lower')\n",
        "\n",
        "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
        "# Plot the centroids as a white X\n",
        "centroids = kmeans.cluster_centers_\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "            marker='x', s=169, linewidths=3,\n",
        "            color='w', zorder=10)\n",
        "plt.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
        "          'Centroids are marked with white cross')\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq7qAK0-gb7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "\n",
        "digits = load_digits()\n",
        "data = scale(digits.data)\n",
        "y = digits.target\n",
        "\n",
        "k = 10\n",
        "samples, features = data.shape\n",
        "\n",
        "\n",
        "def bench_k_means(estimator, name, data):\n",
        "    estimator.fit(data)\n",
        "    print('%-9s\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
        "          % (name, estimator.inertia_,\n",
        "             metrics.homogeneity_score(y, estimator.labels_),\n",
        "             metrics.completeness_score(y, estimator.labels_),\n",
        "             metrics.v_measure_score(y, estimator.labels_),\n",
        "             metrics.adjusted_rand_score(y, estimator.labels_),\n",
        "             metrics.adjusted_mutual_info_score(y,  estimator.labels_),\n",
        "             metrics.silhouette_score(data, estimator.labels_,\n",
        "                                      metric='euclidean')))\n",
        "\n",
        "clf = KMeans(n_clusters=k, init=\"random\", n_init=10)\n",
        "bench_k_means(clf, \"1\", data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}